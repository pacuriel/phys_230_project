{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888f8b48",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline for CIL Project\n",
    "This notebook loads all `*spots.csv` files in the current directory, cleans them, detects cell–cell contact events indicative of contact-inhibition-of-locomotion (CIL), and exports frame‑level and track‑level feature tables ready for machine‑learning and ABM calibration.\n",
    "\n",
    "*Created on 2025-04-29*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96291af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# ---------- run it on all your files -----------------------------------------\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m spots_tables \u001b[38;5;241m=\u001b[39m [load_spots(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m SPOTS_FILES]\n\u001b[1;32m     64\u001b[0m spots        \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(spots_tables, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(spots)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(SPOTS_FILES)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m, in \u001b[0;36mload_spots\u001b[0;34m(path, skip_header_rows)\u001b[0m\n\u001b[1;32m     33\u001b[0m csv_buffer \u001b[38;5;241m=\u001b[39m StringIO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(good_rows))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Read *all columns as string* so nothing blows up\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_buffer, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# ➍ Use the first row as real column names, then drop it\u001b[39;00m\n\u001b[1;32m     39\u001b[0m df_raw\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df_raw\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[0;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m   1969\u001b[0m         new_col_dict,\n\u001b[1;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[1;32m   1973\u001b[0m     )\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/internals/construction.py:443\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m Series(data, index\u001b[38;5;241m=\u001b[39mcolumns, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m    444\u001b[0m     missing \u001b[38;5;241m=\u001b[39m arrays\u001b[38;5;241m.\u001b[39misna()\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# GH10856\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# raise ValueError if only scalars in dict\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/series.py:490\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    487\u001b[0m name \u001b[38;5;241m=\u001b[39m ibase\u001b[38;5;241m.\u001b[39mmaybe_extract_name(name, data, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dtype(dtype)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/indexes/base.py:7647\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7645\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_arrays(index_like)\n\u001b[1;32m   7646\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 7647\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   7648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(index_like, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/indexes/base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    562\u001b[0m         data \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     arr \u001b[38;5;241m=\u001b[39m sanitize_array(data, \u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex must be specified when data is not list-like\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/construction.py:654\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_convert_platform(data)\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    656\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:139\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m    138\u001b[0m     arr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, arr)\n\u001b[0;32m--> 139\u001b[0m     arr \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(arr)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32mlib.pyx:2538\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert numpy.ndarray to numpy.ndarray"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR   = Path(\".\")\n",
    "SPOTS_FILES = sorted(DATA_DIR.glob(\"*spots.csv\"))\n",
    "\n",
    "def load_spots(path: Path, skip_header_rows: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Return a clean TrackMate spots DataFrame (TrackID, Frame, T, X, Y, Movie).\"\"\"\n",
    "    lines = path.read_text(encoding=\"latin1\").splitlines()\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # ➊ Keep everything *after* the three descriptive lines\n",
    "    # ------------------------------------------------------------------ #\n",
    "    body = lines[skip_header_rows:]\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # ➋ Determine the expected number of commas from the *first* row\n",
    "    #    (TrackMate always writes a fixed-width table after the header)\n",
    "    # ------------------------------------------------------------------ #\n",
    "    header_like   = body[0]\n",
    "    expected_commas = header_like.count(\",\")\n",
    "\n",
    "    good_rows = []\n",
    "    for ln in body:\n",
    "        if ln.count(\",\") == expected_commas:      # perfect width ➜ keep\n",
    "            good_rows.append(ln)\n",
    "        # else:  drop the row silently\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # ➌ Load the kept rows with pandas (no dtype inference)\n",
    "    # ------------------------------------------------------------------ #\n",
    "    from io import StringIO\n",
    "    csv_buffer = StringIO(\"\\n\".join(good_rows))\n",
    "\n",
    "    # Read *all columns as string* so nothing blows up\n",
    "    df_raw = pd.read_csv(csv_buffer, dtype=str, header=None)\n",
    "\n",
    "    # ➍ Use the first row as real column names, then drop it\n",
    "    df_raw.columns = df_raw.iloc[0]\n",
    "    df_raw = df_raw.drop(index=df_raw.index[0]).reset_index(drop=True)\n",
    "\n",
    "    # ➎ Rename and reduce to essentials\n",
    "    rename = {\n",
    "        \"TRACK_ID\": \"TrackID\",     \"TRACK_INDEX\": \"TrackID\",\n",
    "        \"Frame\": \"Frame\",          \"FRAME\": \"Frame\",\n",
    "        \"POSITION_X\": \"X\",         \"(µm)\": \"X\",\n",
    "        \"POSITION_Y\": \"Y\",         \"(µm).1\": \"Y\",\n",
    "        \"POSITION_T\": \"T\",         \"(sec)\": \"T\",\n",
    "    }\n",
    "    df = df_raw.rename(columns={c: rename.get(c, c) for c in df_raw.columns})\n",
    "    df = df[[\"TrackID\", \"Frame\", \"T\", \"X\", \"Y\"]]\n",
    "\n",
    "    # ➏ Cast numeric columns\n",
    "    for col in [\"TrackID\", \"Frame\", \"T\", \"X\", \"Y\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # ➐ Drop rows with missing essentials and tag the movie name\n",
    "    df = df.dropna(subset=[\"TrackID\", \"Frame\", \"X\", \"Y\"])\n",
    "    df[\"Movie\"] = path.stem\n",
    "    return df\n",
    "\n",
    "# ---------- run it on all your files -----------------------------------------\n",
    "spots_tables = [load_spots(p) for p in SPOTS_FILES]\n",
    "spots        = pd.concat(spots_tables, ignore_index=True)\n",
    "\n",
    "print(f\"✅ Loaded {len(spots):,} rows from {len(SPOTS_FILES)} files\")\n",
    "spots.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# basic sanity checks\n",
    "print('Unique movies:', spots['Movie'].unique())\n",
    "print('Tracks:', spots['TrackID'].nunique())\n",
    "print(spots.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameter: distance threshold for a 'contact' event (microns)\n",
    "R_CIL = 25.0\n",
    "\n",
    "# Detect contacts frame-by-frame within each movie\n",
    "contacts = []\n",
    "for movie, grp in spots.groupby('Movie'):\n",
    "    for frame, fdf in grp.groupby('Frame'):\n",
    "        coords = fdf[['X','Y']].values\n",
    "        idx = fdf.index.values\n",
    "        from scipy.spatial.distance import pdist, squareform\n",
    "        D = squareform(pdist(coords))\n",
    "        pairs = np.argwhere(np.triu((D < R_CIL) & (D>0), k=1))\n",
    "        for i,j in pairs:\n",
    "            contacts.append({'Movie':movie,'Frame':frame,\n",
    "                             'Track_i':fdf.loc[idx[i],'TrackID'],\n",
    "                             'Track_j':fdf.loc[idx[j],'TrackID'],\n",
    "                             'dist':D[i,j]})\n",
    "contacts = pd.DataFrame(contacts)\n",
    "contacts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flag each spot row if it is in contact\n",
    "spots['in_contact'] = False\n",
    "if not contacts.empty:\n",
    "    key = contacts[['Movie','Frame','Track_i']]\n",
    "    spots.loc[pd.MultiIndex.from_frame(key).isin(spots.set_index(['Movie','Frame','TrackID']).index),'in_contact']=True\n",
    "    key = contacts[['Movie','Frame','Track_j']]\n",
    "    spots.loc[pd.MultiIndex.from_frame(key).isin(spots.set_index(['Movie','Frame','TrackID']).index),'in_contact']=True\n",
    "spots.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute per-frame instantaneous speed and turn angle\n",
    "spots = spots.sort_values(['Movie','TrackID','Frame'])\n",
    "spots['dX'] = spots.groupby(['Movie','TrackID'])['X'].diff()\n",
    "spots['dY'] = spots.groupby(['Movie','TrackID'])['Y'].diff()\n",
    "spots['dt'] = spots.groupby(['Movie','TrackID'])['T'].diff()\n",
    "spots['speed'] = np.sqrt(spots.dX**2 + spots.dY**2)/spots.dt\n",
    "spots['angle'] = np.arctan2(spots.dY, spots.dX)\n",
    "spots['dtheta'] = spots.groupby(['Movie','TrackID'])['angle'].diff()\n",
    "\n",
    "# Export frame‑level features\n",
    "spots.to_parquet('features_framelevel.parquet')\n",
    "spots.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate to track level\n",
    "track_feats = (spots.groupby(['Movie','TrackID'])\n",
    "               .agg(total_distance=('speed', lambda s: (s*spots.loc[s.index,'dt']).sum()),\n",
    "                    mean_speed=('speed','mean'),\n",
    "                    confinement_ratio=('speed', lambda s: s.mean()/s.max()),\n",
    "                    contact_fraction=('in_contact','mean'),\n",
    "                    mean_turn_rate=('dtheta','mean'))\n",
    "               .reset_index())\n",
    "track_feats.to_parquet('features_tracklevel.parquet')\n",
    "track_feats.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
